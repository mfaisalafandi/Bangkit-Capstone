{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaqMBKFUsMU1"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/https-deeplearning-ai/tensorflow-1-public/blob/master/C2/W4/ungraded_lab/C2_W4_Lab_1_multi_class_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RhQLSnGP6gX"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrxdR83ANgjS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from shutil import copyfile\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/Bangkit-Malaria/Dataset'\n",
        "\n",
        "parasite_dir = os.path.join(base_dir + '/training', 'parasite')\n",
        "uninfected_dir = os.path.join(base_dir + '/training', 'uninfected')\n",
        "\n",
        "print('total training Parasite images:', len(os.listdir(parasite_dir)))\n",
        "print('total training Uninfected images:', len(os.listdir(uninfected_dir)))\n",
        "\n",
        "parasite_files = os.listdir(parasite_dir)\n",
        "print(parasite_files[:10])\n",
        "\n",
        "uninfected_files = os.listdir(uninfected_dir)\n",
        "print(uninfected_files[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piqohK0Qjopi"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# import zipfile\n",
        "# import random\n",
        "# import shutil\n",
        "# import tensorflow as tf\n",
        "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "# from shutil import copyfile\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# root_dir = '/content/drive/MyDrive/Bangkit-Malaria/Dataset'\n",
        "\n",
        "# # Empty directory to prevent FileExistsError is the function is run several times\n",
        "# if os.path.exists(root_dir):\n",
        "#   shutil.rmtree(root_dir)\n",
        "\n",
        "# def create_train_val_dirs(root_path):\n",
        "#   training_dir = os.path.join(root_dir, 'training')\n",
        "#   validation_dir = os.path.join(root_dir, 'validation')\n",
        "\n",
        "#   training_parasite_dir = os.path.join(training_dir, 'parasite')\n",
        "#   training_uninfected_dir = os.path.join(training_dir, 'uninfected')\n",
        "\n",
        "#   validation_parasite_dir = os.path.join(validation_dir, 'parasite')\n",
        "#   validation_uninfected_dir = os.path.join(validation_dir, 'uninfected')\n",
        "\n",
        "#   os.makedirs(training_parasite_dir)\n",
        "#   os.makedirs(training_uninfected_dir)\n",
        "#   os.makedirs(validation_parasite_dir)\n",
        "#   os.makedirs(validation_uninfected_dir)\n",
        "\n",
        "# try:\n",
        "#   create_train_val_dirs(root_path=root_dir)\n",
        "# except FileExistsError:\n",
        "#   print(\"You should not be seeing this since the upper directory is removed beforehand\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jp9dLel9N9DS"
      },
      "outputs": [],
      "source": [
        "# for rootdir, dirs, files in os.walk(root_dir):\n",
        "#     for subdir in dirs:\n",
        "#         print(os.path.join(rootdir, subdir))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mixqngK4g6e2"
      },
      "outputs": [],
      "source": [
        "# from PIL import Image\n",
        "\n",
        "# # Function to resize images\n",
        "# def resize_images(image_paths, new_width, new_height):\n",
        "#     resized_images = []\n",
        "#     for img_path in image_paths:\n",
        "#         img = Image.open(img_path)\n",
        "#         resized_img = img.resize((new_width, new_height))\n",
        "#         resized_images.append(resized_img)\n",
        "#     return resized_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSpDDXkdhCe6"
      },
      "outputs": [],
      "source": [
        "# # Define the new dimensions\n",
        "# new_width = 150\n",
        "# new_height = 150\n",
        "\n",
        "# # Resizing Parasite images\n",
        "# resized_parasite = resize_images([os.path.join(parasite_dir, fname) for fname in parasite_files[:2]], new_width, new_height)\n",
        "\n",
        "# # Resizing Uninfected images\n",
        "# resized_uninfected = resize_images([os.path.join(uninfected_dir, fname) for fname in uninfected_files[:2]], new_width, new_height)\n",
        "\n",
        "# # Display the resized images\n",
        "# fig, axes = plt.subplots(2, 2, figsize=(8, 8))\n",
        "\n",
        "# for i, ax in enumerate(axes.flat):\n",
        "#     if i < 2:\n",
        "#         ax.imshow(resized_parasite[i])\n",
        "#         ax.set_title(\"Resized Parasite\")\n",
        "#     else:\n",
        "#         ax.imshow(resized_uninfected[i - 2])\n",
        "#         ax.set_title(\"Resized Uninfected\")\n",
        "#     ax.axis('off')\n",
        "\n",
        "# plt.tight_layout()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwFxzeSn0VEH"
      },
      "outputs": [],
      "source": [
        "def train_val_generators(TRAINING_DIR, VALIDATION_DIR):\n",
        "  # Instantiate the ImageDataGenerator class (don't forget to set the rescale argument)\n",
        "  train_datagen = ImageDataGenerator(rescale = 1.0/255.0)\n",
        "\n",
        "  # Pass in the appropriate arguments to the flow_from_directory method\n",
        "  train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n",
        "                                                      batch_size=150,\n",
        "                                                      class_mode='binary',\n",
        "                                                      target_size=(150, 150))\n",
        "\n",
        "  # Instantiate the ImageDataGenerator class (don't forget to set the rescale argument)\n",
        "  validation_datagen = ImageDataGenerator(rescale = 1.0/255.0)\n",
        "\n",
        "  # Pass in the appropriate arguments to the flow_from_directory method\n",
        "  validation_generator = validation_datagen.flow_from_directory(directory=VALIDATION_DIR,\n",
        "                                                                batch_size=150,\n",
        "                                                                class_mode='binary',\n",
        "                                                                target_size=(150, 150))\n",
        "  ### END CODE HERE\n",
        "  return train_generator, validation_generator\n",
        "\n",
        "TRAINING_DIR = base_dir + \"/training\"\n",
        "VALIDATION_DIR = base_dir + \"/validation\"\n",
        "\n",
        "train_generator, validation_generator = train_val_generators(TRAINING_DIR, VALIDATION_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ps7kIRaFRIC"
      },
      "source": [
        "## Prepare the ImageDataGenerator\n",
        "\n",
        "You will prepare the generators as before. You will set the training set up for data augmentation so it can mimick other poses that the model needs to learn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWTisYLQM1aM"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "TRAINING_DIR = base_dir + \"/training\"\n",
        "training_datagen = ImageDataGenerator(\n",
        "      rescale = 1.0/255.0,\n",
        "\t    rotation_range=40, #\n",
        "      # width_shift_range=0.2, #\n",
        "      # height_shift_range=0.2, #\n",
        "      shear_range=0.2,\n",
        "      # zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "VALIDATION_DIR = base_dir + \"/validation\"\n",
        "validation_datagen = ImageDataGenerator(rescale = 1.0/255.0)\n",
        "\n",
        "train_generator = training_datagen.flow_from_directory(\n",
        "\tTRAINING_DIR,\n",
        "\ttarget_size=(150,150),\n",
        "\tclass_mode='binary',\n",
        "  batch_size=150\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "\tVALIDATION_DIR,\n",
        "\ttarget_size=(150,150),\n",
        "\tclass_mode='binary',\n",
        "  batch_size=150\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLZ51D3BoyKL"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    # tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(64, 64, 3)),\n",
        "    # tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # tf.keras.layers.Dropout(0.2),\n",
        "    # tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    # tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # tf.keras.layers.Dropout(0.2),\n",
        "    # tf.keras.layers.Flatten(),\n",
        "    # tf.keras.layers.Dense(512, activation='relu'),\n",
        "    # tf.keras.layers.Dropout(0.2),\n",
        "    # tf.keras.layers.Dense(256, activation='relu'),\n",
        "    # tf.keras.layers.Dropout(0.2),\n",
        "    # tf.keras.layers.Dense(2, activation='sigmoid')\n",
        "\n",
        "    # tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    # tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    # tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # tf.keras.layers.Flatten(),\n",
        "    # tf.keras.layers.Dropout(0.2),\n",
        "    # # tf.keras.layers.Dense(512, activation='relu'),\n",
        "    # tf.keras.layers.Dense(124, activation='relu'),\n",
        "    # tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "\n",
        "    # tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    # tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    # tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    # tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # tf.keras.layers.Flatten(),\n",
        "    # tf.keras.layers.Dense(512, activation='relu'),\n",
        "    # tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "\n",
        "    # tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    # tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # tf.keras.layers.Flatten(),\n",
        "    # tf.keras.layers.Dense(124, activation='relu'),\n",
        "    # tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "\n",
        "    # tf.keras.layers.Flatten(input_shape=(64, 64, 3)),\n",
        "    # tf.keras.layers.Dense(124, activation='relu'),\n",
        "    # tf.keras.layers.Dropout(0.2),\n",
        "    # tf.keras.layers.Dense(62, activation='relu'),\n",
        "    # tf.keras.layers.Dense(2, activation='softmax')\n",
        "\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n",
        "\n",
        "# Set the training parameters\n",
        "model.compile(optimizer='adam',\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# model.compile(optimizer='adam',\n",
        "#                 loss='categorical_crossentropy',\n",
        "#                 metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mHX5L7HFXQ7"
      },
      "outputs": [],
      "source": [
        "# ?# Train the model\n",
        "# history = model.fit(train_generator, epochs=20, steps_per_epoch=30, validation_data = validation_generator, verbose = 1, validation_steps=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5JhQ2kepHVQ"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_generator,\n",
        "                    epochs=18,\n",
        "                    verbose=1,\n",
        "                    validation_data=validation_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aeTRVCr6aosw"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the results\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3ps8Q1tpYMG"
      },
      "source": [
        "# **Model Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZABJp7T3VLCU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "\n",
        "  # predicting images\n",
        "  path = fn\n",
        "  img = load_img(path, target_size=(150, 150))\n",
        "  x = img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  prediction = \"unparasite\" if classes[0][0] == 1 else \"parasite\"\n",
        "\n",
        "  print(fn)\n",
        "  print(classes)\n",
        "  print(prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIOXFLlcdLUs"
      },
      "source": [
        "# **Export The Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4d3RPm6gPGx"
      },
      "outputs": [],
      "source": [
        "export_dir = 'saved_model/1'\n",
        "\n",
        "# YOUR CODE HERE\n",
        "tf.saved_model.save(model, export_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NsVelhKRgPlX"
      },
      "outputs": [],
      "source": [
        "# Select mode of optimization\n",
        "mode = \"Speed\"\n",
        "\n",
        "if mode == 'Storage':\n",
        "    optimization = tf.lite.Optimize.OPTIMIZE_FOR_SIZE\n",
        "elif mode == 'Speed':\n",
        "    optimization = tf.lite.Optimize.OPTIMIZE_FOR_LATENCY\n",
        "else:\n",
        "    optimization = tf.lite.Optimize.DEFAULT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NiUWqOM0gTVm"
      },
      "outputs": [],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)\n",
        "\n",
        "# Set the optimzations\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "# Invoke the converter to finally generate the TFLite model\n",
        "tflite_model = converter.convert()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96OTLr-zgW4b"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "\n",
        "tflite_model_file = pathlib.Path('./model.tflite')\n",
        "tflite_model_file.write_bytes(tflite_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVLzqHbCRzmv"
      },
      "source": [
        "# **H5**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBxgSsG5R10y"
      },
      "outputs": [],
      "source": [
        "model.save('malaria_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rgnj9bvEgZNX"
      },
      "source": [
        "# **Test**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QI85mK1pr90i"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\faisal\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\faisal\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\faisal\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "loaded_model = load_model('malaria_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXIFeyjFr_HI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "\n",
        "  # predicting images\n",
        "  path = fn\n",
        "  img = load_img(path, target_size=(150, 150))\n",
        "  x = img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = loaded_model.predict(images, batch_size=10)\n",
        "  prediction = \"unparasite\" if classes[0][0] == 1 else \"parasite\"\n",
        "\n",
        "  print(fn)\n",
        "  print(classes)\n",
        "  print(prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## VS Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PB26-6WtsR2L"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 38ms/step\n",
            "[[0.]]\n",
            "parasite\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "path = './data/parasite/2.png'  # Ganti dengan path gambar yang diunggah\n",
        "# path = './data/uninfected/2.png'  # Ganti dengan path gambar yang diunggah\n",
        "\n",
        "# img = image.load_img(path, target_size=(150, 150))\n",
        "# x = image.img_to_array(img)\n",
        "# x = np.expand_dims(x, axis=0)\n",
        "# images = np.vstack([x])\n",
        "\n",
        "img = Image.open(path)\n",
        "img = img.resize((150, 150))  # Resize the image\n",
        "x = np.array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "images = np.vstack([x])\n",
        "\n",
        "# Predict the class of the image\n",
        "classes = loaded_model.predict(images, batch_size=10)\n",
        "prediction = \"unparasite\" if classes[0][0] == 1 else \"parasite\"\n",
        "\n",
        "print(classes)\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsQAgMRdsR7q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6lVOjyksR-c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "larI_PDZsSBY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHFWD8q5sSEY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hH-30LrDr_MF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VT3RZ1wr_O5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ek_qcEyjr_Rg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFjYBZQur_UH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wl64ac68r_Wo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QuiO6rhgPpQ"
      },
      "outputs": [],
      "source": [
        "# Load TFLite model and allocate tensors.\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "output_index = interpreter.get_output_details()[0][\"index\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCkrl9xpgbH_"
      },
      "outputs": [],
      "source": [
        "# Gather results for the randomly sampled test images\n",
        "predictions = []\n",
        "test_labels = []\n",
        "test_images = []\n",
        "\n",
        "for img, label in test_batches.take(50):\n",
        "    interpreter.set_tensor(input_index, img)\n",
        "    interpreter.invoke()\n",
        "    predictions.append(interpreter.get_tensor(output_index))\n",
        "    test_labels.append(label[0])\n",
        "    test_images.append(np.array(img))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KStvzdqUgbNa"
      },
      "outputs": [],
      "source": [
        "# Utilities functions for plotting\n",
        "\n",
        "def plot_image(i, predictions_array, true_label, img):\n",
        "    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
        "    plt.grid(False)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "\n",
        "    img = np.squeeze(img)\n",
        "\n",
        "    plt.imshow(img, cmap=plt.cm.binary)\n",
        "\n",
        "    predicted_label = np.argmax(predictions_array)\n",
        "\n",
        "    if predicted_label == true_label.numpy():\n",
        "        color = 'green'\n",
        "    else:\n",
        "        color = 'red'\n",
        "\n",
        "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
        "                                         100*np.max(predictions_array),\n",
        "                                         class_names[true_label]),\n",
        "                                         color=color)\n",
        "\n",
        "def plot_value_array(i, predictions_array, true_label):\n",
        "    predictions_array, true_label = predictions_array[i], true_label[i]\n",
        "    plt.grid(False)\n",
        "    plt.xticks(list(range(10)))\n",
        "    plt.yticks([])\n",
        "    thisplot = plt.bar(range(10), predictions_array[0], color=\"#777777\")\n",
        "    plt.ylim([0, 1])\n",
        "    predicted_label = np.argmax(predictions_array[0])\n",
        "\n",
        "    thisplot[predicted_label].set_color('red')\n",
        "    thisplot[true_label].set_color('blue')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YW__xsGTgbS-"
      },
      "outputs": [],
      "source": [
        "# Visualize the outputs\n",
        "\n",
        "# Select index of image to display. Minimum index value is 1 and max index value is 50.\n",
        "index = 49\n",
        "\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(index, predictions, test_labels, test_images)\n",
        "plt.subplot(1,2,2)\n",
        "plot_value_array(index, predictions, test_labels)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPow0pr6gbXS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-g9fGJ0QgbcI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhQLoWsecl90"
      },
      "outputs": [],
      "source": [
        "MALARIA_SAVED_MODEL = \"malaria_saved_model\"\n",
        "\n",
        "tf.saved_model.save(model, MALARIA_SAVED_MODEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxJ7FLWCdDu6"
      },
      "outputs": [],
      "source": [
        "%%bash -s $MALARIA_SAVED_MODEL\n",
        "saved_model_cli show --dir $1 --tag_set serve --signature_def serving_default"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFbqnbpJdEga"
      },
      "outputs": [],
      "source": [
        "loaded = tf.saved_model.load(MALARIA_SAVED_MODEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doUFEIL3dEqG"
      },
      "outputs": [],
      "source": [
        "print(list(loaded.signatures.keys()))\n",
        "infer = loaded.signatures[\"serving_default\"]\n",
        "print(infer.structured_input_signature)\n",
        "print(infer.structured_outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8wfUxgNdUwu"
      },
      "source": [
        "# **Convert To TfLite**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeBpInT3dKiN"
      },
      "outputs": [],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model(MALARIA_SAVED_MODEL)\n",
        "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "tflite_model = converter.convert()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LJakXl6dcdq"
      },
      "outputs": [],
      "source": [
        "tflite_model_file = 'converted_model.tflite'\n",
        "\n",
        "with open(tflite_model_file, \"wb\") as f:\n",
        "    f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lcpEsiieQGR"
      },
      "source": [
        "Prep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsjEV3Oid4e_"
      },
      "outputs": [],
      "source": [
        "# Load TFLite model and allocate tensors.\n",
        "with open(tflite_model_file, 'rb') as fid:\n",
        "    tflite_model = fid.read()\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "output_index = interpreter.get_output_details()[0][\"index\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0yju7G-XeHg_"
      },
      "outputs": [],
      "source": [
        "# Gather results for the randomly sampled test images\n",
        "predictions = []\n",
        "\n",
        "test_labels, test_imgs = [], []\n",
        "for img, label in tqdm(test_batches.take(10)):\n",
        "    interpreter.set_tensor(input_index, img)\n",
        "    interpreter.invoke()\n",
        "    predictions.append(interpreter.get_tensor(output_index))\n",
        "\n",
        "    test_labels.append(label.numpy()[0])\n",
        "    test_imgs.append(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCkFRFTdeJMA"
      },
      "outputs": [],
      "source": [
        "#@title Visualize the outputs { run: \"auto\" }\n",
        "index = 0 #@param {type:\"slider\", min:0, max:9, step:1}\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(index, predictions, test_labels, test_imgs)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9RhNE79eLNJ"
      },
      "outputs": [],
      "source": [
        "with open('labels.txt', 'w') as f:\n",
        "    f.write('\\n'.join(class_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4YF63VueMvY"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from google.colab import files\n",
        "    files.download('converted_model.tflite')\n",
        "    files.download('labels.txt')\n",
        "except:\n",
        "    pass"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
